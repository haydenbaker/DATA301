{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Training Error\n",
    "\n",
    "In the previous sections, we learned to build regression models. In this section, we will learn one way to evaluate the quality of a regression model: the training error. We will also discuss the shortcomings of using training error to measure the quality of a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>2929</td>\n",
       "      <td>924100070</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10010</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>2930</td>\n",
       "      <td>924151050</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>188000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2930 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0         1  526301100           20        RL         141.0     31770   Pave   \n",
       "1         2  526350040           20        RH          80.0     11622   Pave   \n",
       "...     ...        ...          ...       ...           ...       ...    ...   \n",
       "2928   2929  924100070           20        RL          77.0     10010   Pave   \n",
       "2929   2930  924151050           60        RL          74.0      9627   Pave   \n",
       "\n",
       "     Alley Lot Shape Land Contour    ...     Pool Area Pool QC  Fence  \\\n",
       "0      NaN       IR1          Lvl    ...             0     NaN    NaN   \n",
       "1      NaN       Reg          Lvl    ...             0     NaN  MnPrv   \n",
       "...    ...       ...          ...    ...           ...     ...    ...   \n",
       "2928   NaN       Reg          Lvl    ...             0     NaN    NaN   \n",
       "2929   NaN       Reg          Lvl    ...             0     NaN    NaN   \n",
       "\n",
       "     Misc Feature Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  \\\n",
       "0             NaN        0       5    2010       WD           Normal   \n",
       "1             NaN        0       6    2010       WD           Normal   \n",
       "...           ...      ...     ...     ...       ...             ...   \n",
       "2928          NaN        0       4    2006       WD           Normal   \n",
       "2929          NaN        0      11    2006       WD           Normal   \n",
       "\n",
       "      SalePrice  \n",
       "0        215000  \n",
       "1        105000  \n",
       "...         ...  \n",
       "2928     170000  \n",
       "2929     188000  \n",
       "\n",
       "[2930 rows x 82 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 5\n",
    "\n",
    "housing = pd.read_csv(\"https://raw.githubusercontent.com/dlsun/data-science-book/master/data/AmesHousing.txt\",\n",
    "                      sep=\"\\t\")\n",
    "housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics for Regression Models\n",
    "\n",
    "To evaluate the performance of a regression model, we compare the predicted labels from the model against the true labels. Since the labels are quantitative, it makes sense to look at the difference between each predicted label $\\hat y_i$ and the true label $y_i$. \n",
    "\n",
    "One way to make sense of these differences is to square each difference and average the squared differences. This measure of error is known as **mean squared error** (or **MSE**, for short):\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "\\textrm{MSE} &= \\textrm{mean of } (y_i - \\hat y_i)^2.\n",
    "\\end{align*}\n",
    "$$ \n",
    "\n",
    "MSE is difficult to interpret because its units are the square of the units of $y$. To make MSE more interpretable, it is common to take the _square root_ of the MSE to obtain the **root mean squared error** (or RMSE, for short):\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "\\textrm{RMSE} &= \\sqrt{\\textrm{MSE}}.\n",
    "\\end{align*}\n",
    "$$ \n",
    "\n",
    "The RMSE measures how off a \"typical\" prediction is. Notice that the reasoning above is exactly the same reasoning that we used in Chapter 1 when we defined the variance and the standard deviation.\n",
    "\n",
    "Another common measure of error is the **mean absolute error** (or **MAE**, for short):\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "\\textrm{MAE} &= \\textrm{mean of } |y_i - \\hat y_i|.\n",
    "\\end{align*}\n",
    "$$ \n",
    "\n",
    "Like the RMSE, the MAE measures how off a \"typical\" prediction is. There are other metrics that can be used to measure the quality of a regression model, but these are the most common ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Error\n",
    "\n",
    "To calculate the MSE, RMSE, or MAE, we need data where the true labels are known. Where do we find such data? One natural source of labeled data is the training data, since we needed the true labels to be able to train a model.\n",
    "\n",
    "For a $k$-nearest neighbors model, the training data is the data from which the $k$-nearest neighbors are selected. So to calculate the training RMSE, we do the following:\n",
    "\n",
    "For each observation in the training data:\n",
    "1. Find its $k$-nearest neighbors in the training data.\n",
    "2. Average the labels of the $k$-nearest neighbors to obtain the predicted label.\n",
    "3. Subtract the predicted label from the true label.\n",
    "\n",
    "At this point, we can average the square of these differences to obtain the MSE or average their absolute values to obtain the MAE.\n",
    "\n",
    "Let's calculate the training MSE for a 10-nearest neighbors model for house price using a subset of features from the Ames housing data set. First, we extract the variables that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features in our model. All quantitative, except Neighborhood.\n",
    "features = [\"Lot Area\", \"Gr Liv Area\",\n",
    "            \"Full Bath\", \"Half Bath\",\n",
    "            \"Bedroom AbvGr\", \n",
    "            \"Year Built\", \"Yr Sold\",\n",
    "            \"Neighborhood\"]\n",
    "\n",
    "X_train_dict = housing[features].to_dict(orient=\"records\")\n",
    "y_train = housing[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use Scikit-Learn to preprocess the features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(X_train_dict)\n",
    "X_train = vec.transform(X_train_dict)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_sc = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and to fit the $k$-nearest neighbors model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 164090. ,  131512.5,  154860. , ...,  128530. ,  140600. ,  201800. ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Fit a 10-nearest neighbors model.\n",
    "model = KNeighborsRegressor(n_neighbors=10)\n",
    "model.fit(X_train_sc, y_train)\n",
    "\n",
    "# Calculate the model predictions on the training data.\n",
    "y_train_pred = model.predict(X_train_sc)\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to compare these predictions to the true labels, which we know, since this is the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1139920438.2806828"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean-squared error.\n",
    "mse = ((y_train - y_train_pred) ** 2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This number is very large and not very interpretable (because it is in units of \"dollars squared\"). Let's take the square root to obtain the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33762.707804331731"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE says that our model's predictions are, on average, off by about \\\\$33,000. This is not great, but it is also not too bad when an average house is worth about \\\\$180,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem with Training Error\n",
    "\n",
    "Training error is not a great measure of the quality of a model. To see why, consider a 1-nearest neighbor regression model. Before you read on, can you guess what the training error of a 1-nearest neighbor regression model will be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.846416382252556"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a 1-nearest neighbors model.\n",
    "model = KNeighborsRegressor(n_neighbors=1)\n",
    "model.fit(X_train_sc, y_train)\n",
    "\n",
    "# Calculate the model predictions on the training data.\n",
    "y_train_pred = model.predict(X_train_sc)\n",
    "\n",
    "# Calculate the MAE\n",
    "(y_train - y_train_pred).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training error of this model seems too good to be true. Can our model really be off by just \\$57.85 on average?\n",
    "\n",
    "The error is so small because the nearest neighbor to any observation in the training data will be the observation itself! In fact, if we look at the vector of differences between the true and predicted labels, we see that most of the differences are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "       ... \n",
       "2928    0.0\n",
       "2929    0.0\n",
       "Name: SalePrice, Length: 2930, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train - y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why isn't the MSE exactly equal to 0, then? That is because there may be multiple houses in the training data with the exact same values for all of the features, so there may be multiple observations that are a distance of 0.0 away. Any one of these observations has equal claim to being the \"1-nearest neighbor\". If we happen to select one of the _other_ houses in the training data as the nearest neighbor, then its price will in general be different.\n",
    "\n",
    "How many predictions did the 1-nearest neighbor model get wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train != y_train_pred).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1-nearest neighbor model nailed the price exactly for all but 22 of the 2930 houses, so the training error is small.\n",
    "\n",
    "Of course, a 1-nearest neighbor is unlikely to be the best model for predicting house prices. If one house in the training data happened to cost \\\\$10,000,000, it would not be sensible to predict another house to cost \\\\$10,000,000 -- even one very similar to it. This is why we usually average over multiple neighbors (i.e., $k$ neighbors) to make predictions.  \n",
    "\n",
    "In the next section, we will learn a better way to measure the quality of a model than training error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** Using the Tips data set (`https://raw.githubusercontent.com/dlsun/data-science-book/master/data/tips.csv`), train $k$-nearest neighbors regression models to predict the tip for different values of $k$. Calculate the training MAE of each model and make a plot showing this training error as a function of $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips_df = pd.read_csv(\"https://raw.githubusercontent.com/dlsun/data-science-book/master/data/tips.csv\")\n",
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the data to inputs and output \n",
    "X_train_dict = tips_df[[\"total_bill\", \"sex\", \"smoker\", \"day\", \"time\", \"size\"]].to_dict(orient=\"records\")\n",
    "Y_train = tips_df[\"tip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the data to the vectorizer object and transform the data\n",
    "vec = DictVectorizer(sparse=False)\n",
    "vec.fit(X_train_dict)\n",
    "X_train = vec.transform(X_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the data to the scaler object and transform it\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_sc = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.752,  2.17 ,  3.214,  3.064,  3.737,  3.784,  2.115,  4.084,\n",
       "        2.386,  2.386,  2.115,  3.671,  2.436,  3.112,  2.752,  3.064,\n",
       "        2.752,  2.639,  2.752,  3.022,  3.007,  2.73 ,  2.73 ,  4.983,\n",
       "        3.007,  2.713,  2.05 ,  2.05 ,  3.007,  2.73 ,  2.05 ,  2.713,\n",
       "        2.73 ,  3.072,  3.007,  3.451,  2.665,  2.825,  2.963,  4.085,\n",
       "        2.665,  2.661,  2.386,  2.115,  4.089,  2.997,  3.064,  4.089,\n",
       "        4.037,  2.747,  2.302,  2.752,  3.671,  2.115,  4.084,  3.005,\n",
       "        3.65 ,  2.89 ,  1.957,  5.683,  2.856,  2.121,  1.957,  3.268,\n",
       "        2.665,  3.04 ,  2.73 ,  2.58 ,  3.007,  2.121,  2.05 ,  2.825,\n",
       "        3.283,  3.283,  2.73 ,  2.05 ,  2.524,  3.794,  2.999,  2.614,\n",
       "        3.058,  2.545,  1.701,  3.058,  2.545,  3.553,  2.416,  2.614,\n",
       "        2.967,  2.999,  3.103,  3.178,  2.653,  2.853,  2.905,  3.291,\n",
       "        3.103,  2.73 ,  3.103,  2.955,  2.653,  2.653,  4.326,  3.283,\n",
       "        2.73 ,  2.121,  2.856,  2.941,  3.007,  2.794,  2.282,  2.68 ,\n",
       "        4.287,  3.064,  3.459,  2.752,  4.089,  1.77 ,  1.938,  3.253,\n",
       "        2.089,  1.988,  2.418,  2.545,  1.938,  4.218,  2.089,  2.218,\n",
       "        1.938,  3.167,  2.999,  2.463,  1.938,  1.938,  2.463,  1.77 ,\n",
       "        1.77 ,  2.068,  3.058,  1.988,  2.463,  4.502,  4.402,  4.218,\n",
       "        2.463,  1.77 ,  2.459,  1.938,  2.089,  2.089,  2.386,  2.303,\n",
       "        2.863,  3.784,  3.317,  3.887,  4.734,  3.737,  2.752,  3.3  ,\n",
       "        3.534,  2.302,  2.752,  2.303,  3.014,  3.239,  3.064,  4.089,\n",
       "        2.58 ,  2.58 ,  3.803,  2.244,  3.709,  3.349,  3.414,  3.349,\n",
       "        3.414,  3.414,  3.099,  3.567,  3.817,  3.414,  3.817,  3.451,\n",
       "        3.567,  3.474,  3.75 ,  4.385,  3.267,  3.549,  3.414,  2.781,\n",
       "        3.058,  3.058,  3.058,  2.089,  3.058,  3.877,  2.468,  3.058,\n",
       "        3.058,  2.5  ,  2.468,  2.698,  3.058,  2.709,  2.912,  3.65 ,\n",
       "        2.764,  2.58 ,  2.806,  3.262,  5.683,  2.794,  3.509,  2.58 ,\n",
       "        3.033,  1.957,  1.957,  3.509,  2.518,  2.648,  2.518,  2.667,\n",
       "        2.518,  2.648,  2.318,  2.713,  2.05 ,  3.283,  3.036,  2.423,\n",
       "        2.05 ,  2.05 ,  2.121,  2.05 ,  1.957,  2.841,  2.922,  3.527,\n",
       "        3.283,  2.856,  3.007,  2.948])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a 10-nearest neighbors model.\n",
    "model = KNeighborsRegressor(n_neighbors=10)\n",
    "model.fit(X_train_sc, Y_train)\n",
    "\n",
    "# Calculate the model predictions on the training data.\n",
    "Y_train_pred = model.predict(X_train_sc)\n",
    "Y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74859836065573782"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips_mae = np.mean(abs(Y_train_pred - Y_train))\n",
    "tips_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd44a4f4240>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = pd.Series(range(1, 101))\n",
    "k.index = range(1, 101)\n",
    "\n",
    "def mae(k):\n",
    "    model = KNeighborsRegressor(n_neighbors=k)\n",
    "    model.fit(X_train_sc, Y_train)\n",
    "    Y_train_pred = model.predict(X_train_sc)\n",
    "    return np.mean(abs(Y_train_pred - Y_train)) \n",
    "\n",
    "k.apply(mae).plot.line()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
