{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 Model Selection and Hyperparameter Tuning\n",
    "\n",
    "This section will use the tools developed in the previous section to answer two important questions:\n",
    "\n",
    "- Model Selection: How do we determine which model is best?\n",
    "- Hyperparameter Tuning: How do we choose hyperparameters, such as $k$ in $k$-nearest neighbors?\n",
    "\n",
    "In the previous section, we saw how to use training and validation sets to estimate how well the model will perform on future data. A natural way to decide between competing models (or hyperparameters) is to choose the one that minimizes the validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>2929</td>\n",
       "      <td>924100070</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10010</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>2930</td>\n",
       "      <td>924151050</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>188000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2930 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0         1  526301100           20        RL         141.0     31770   Pave   \n",
       "1         2  526350040           20        RH          80.0     11622   Pave   \n",
       "...     ...        ...          ...       ...           ...       ...    ...   \n",
       "2928   2929  924100070           20        RL          77.0     10010   Pave   \n",
       "2929   2930  924151050           60        RL          74.0      9627   Pave   \n",
       "\n",
       "     Alley Lot Shape Land Contour    ...     Pool Area Pool QC  Fence  \\\n",
       "0      NaN       IR1          Lvl    ...             0     NaN    NaN   \n",
       "1      NaN       Reg          Lvl    ...             0     NaN  MnPrv   \n",
       "...    ...       ...          ...    ...           ...     ...    ...   \n",
       "2928   NaN       Reg          Lvl    ...             0     NaN    NaN   \n",
       "2929   NaN       Reg          Lvl    ...             0     NaN    NaN   \n",
       "\n",
       "     Misc Feature Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  \\\n",
       "0             NaN        0       5    2010       WD           Normal   \n",
       "1             NaN        0       6    2010       WD           Normal   \n",
       "...           ...      ...     ...     ...       ...             ...   \n",
       "2928          NaN        0       4    2006       WD           Normal   \n",
       "2929          NaN        0      11    2006       WD           Normal   \n",
       "\n",
       "      SalePrice  \n",
       "0        215000  \n",
       "1        105000  \n",
       "...         ...  \n",
       "2928     170000  \n",
       "2929     188000  \n",
       "\n",
       "[2930 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 5\n",
    "\n",
    "housing = pd.read_csv(\"https://raw.githubusercontent.com/dlsun/data-science-book/master/data/AmesHousing.txt\",\n",
    "                      sep=\"\\t\")\n",
    "housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $K$-Fold Cross Validation\n",
    "\n",
    "Previously, we carried out cross validation by splitting the data into 2 halves, alternately using one half to train the model and the other to evaluate the model. In general, we can split the data into $k$ subsamples, alternately training the data on $k-1$ subsamples and evaluating the model on the $1$ remaining subsample, i.e., the validation set. This produces $k$ somewhat independent estimates of the test error. This procedure is known as **$k$-fold cross validation**. (Be careful not to confuse the $k$ in $k$-fold cross validation with the $k$ in $k$-nearest neighbors.) Therefore, the specific version of cross validation that we saw earlier is $2$-fold cross validation.\n",
    "\n",
    "A schematic of $4$-fold cross validation is shown below.\n",
    "\n",
    "![](k-folds.png)\n",
    "\n",
    "Implementing $k$-fold cross validation from scratch for $k > 2$ is straightforward but messy, so we will usually let Scikit-Learn do it for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation in Scikit-Learn\n",
    "\n",
    "Scikit-Learn provides a function, `cross_val_score`, that will carry out all aspects of $k$-fold cross validation: \n",
    "\n",
    "1. split the data into $k$ subsamples\n",
    "2. combine the first $k-1$ subsamples into a training set and train the model\n",
    "3. evaluate the model predictions on the last ($k$th) held-out subsample\n",
    "4. repeat steps 2-3 $k$ times (i.e. $k$ \"folds\"), each time holding out a different one of the $k$ subsamples\n",
    "4. calculate $k$ \"scores\", one from each validation set\n",
    "\n",
    "There is one subtlety to keep in mind. Training a $k$-nearest neighbors model is not just about fitting the model; it also involves dummifying the categorical variables and scaling the variables. These preprocessing steps should be included in the cross-validation process. They cannot be done ahead of time.\n",
    "\n",
    "For example, suppose we run $5$-fold cross validation. Then:\n",
    "\n",
    "- When subsamples 1-4 are used for training and subsample 5 for validation, the observations have to be standardized with respect to the mean and SD of subsamples 1-4.\n",
    "- When subsamples 2-5 are used for training and subsample 1 for validation, the observations have to be standardized with respect to the mean and SD of subsamples 2-5.\n",
    "- And so on.\n",
    "\n",
    "We cannot simply standardize all of the data once at the beginning and run cross validation on the standardized data. To do so would be allowing the model to peek at the validation set during training. That's because each training set would be standardized with respect to a mean and SD that is calculated from all data, including the validation set. To be completely above board, we should standardize each training set with respect to the mean and SD of just that training set.\n",
    "\n",
    "Fortunately, Scikit-Learn provides a `Pipeline` object that allows us to chain these preprocessing steps together with the model we want to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# get the features (in dict format) and the labels\n",
    "# (do not split into training and validation sets)\n",
    "features = [\"Lot Area\", \"Gr Liv Area\",\n",
    "            \"Full Bath\", \"Half Bath\",\n",
    "            \"Bedroom AbvGr\", \n",
    "            \"Year Built\", \"Yr Sold\",\n",
    "            \"Neighborhood\"]\n",
    "X_dict = housing[features].to_dict(orient=\"records\")\n",
    "y = housing[\"SalePrice\"]\n",
    "\n",
    "# specify the pipeline\n",
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "model = KNeighborsRegressor(n_neighbors=10)\n",
    "pipeline = Pipeline([(\"vectorizer\", vec), (\"scaler\", scaler), (\"fit\", model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This entire `Pipeline` can be passed to `cross_val_score`, along with the data, the number of folds $k$ (`cv`), and the type of score (`scoring`). So $5$-fold cross validation in Scikit-Learn would look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.98025092e+09,  -1.47950953e+09,  -1.54632969e+09,\n",
       "        -1.87662563e+09,  -1.42167566e+09])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(pipeline, X_dict, y, \n",
    "                         cv=5, scoring=\"neg_mean_squared_error\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we get five (negative) validation MSEs, one from each of the 5 folds. `cross_val_score` returns the _negative_ MSE, instead of the MSE, because by definition, a _higher_ score is better. (Since we want the MSE to be as _low_ as possible, we want the negative MSE to be as _high_ as possible.)\n",
    "\n",
    "To come up with a single overall estimate of the test MSE, we flip the signs and average the MSEs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1660878287.4356349"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE is the square root of the MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40753.874508267734"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(-scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "How do we choose $k$? We can simply try all values of $k$ and pick the one with the smallest (test) MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     1.390511e+09\n",
       "3     1.405909e+09\n",
       "          ...     \n",
       "49    2.208727e+09\n",
       "50    2.216495e+09\n",
       "Length: 50, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# calculates estimate of test error based on 10-fold cross validation\n",
    "def get_cv_error(k):\n",
    "    model = KNeighborsRegressor(n_neighbors=k)\n",
    "    pipeline = Pipeline([(\"vectorizer\", vec), (\"scaler\", scaler), (\"fit\", model)])\n",
    "    mse = np.mean(-cross_val_score(\n",
    "        pipeline, X_dict, y, \n",
    "        cv=10, scoring=\"neg_mean_squared_error\"\n",
    "    ))\n",
    "    return mse\n",
    "    \n",
    "ks = pd.Series(range(1, 51))\n",
    "ks.index = range(1, 51)\n",
    "test_errs = ks.apply(get_cv_error)\n",
    "\n",
    "test_errs.plot.line()\n",
    "test_errs.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE is minimized near $k = 4$, which suggests that a $4$-nearest neighbors model is optimal for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "Suppose we are not sure whether `Yr Sold` should be included in the $4$-nearest neighbors model or not. To determine whether or not it should be included, we can fit a model with `Yr Sold` included and another model with it excluded, and see which model has the better (test) MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = DictVectorizer(sparse=False)\n",
    "scaler = StandardScaler()\n",
    "model = KNeighborsRegressor(n_neighbors=4)\n",
    "pipeline = Pipeline([(\"vectorizer\", vec), (\"scaler\", scaler), (\"fit\", model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Lot Area\", \"Gr Liv Area\",\n",
    "            \"Full Bath\", \"Half Bath\",\n",
    "            \"Bedroom AbvGr\", \n",
    "            \"Year Built\", \"Yr Sold\",\n",
    "            \"Neighborhood\"]\n",
    "X_dict = housing[features].to_dict(orient=\"records\")\n",
    "np.mean(\n",
    "    -cross_val_score(pipeline, X_dict, y, cv=10, scoring=\"neg_mean_squared_error\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Lot Area\", \"Gr Liv Area\",\n",
    "            \"Full Bath\", \"Half Bath\",\n",
    "            \"Bedroom AbvGr\", \n",
    "            \"Year Built\",\n",
    "            \"Neighborhood\"]\n",
    "X_dict = housing[features].to_dict(orient=\"records\")\n",
    "-cross_val_score(pipeline, X_dict, y, cv=10, scoring=\"neg_mean_squared_error\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE actually goes down when we remove `Yr Sold`, so it seems that the model is better off without this variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
